import{_ as e,o as t,c as o,e as a}from"./app-Bmelea3n.js";const r={},n=a('<h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h2><p>LoRA（Low-Rank Adaptation）解决了在机器学习领域，特别是微调大型语言模型时遇到的一个重大挑战。传统的微调方法需要大量的计算资源和存储空间，这对于许多用户来说是不可承受的。LoRA通过显著减少可训练参数的数量，使微调过程更加高效和可行。</p><p>LoRA通过将权重更新分解为低秩矩阵来实现这一点。与其在微调过程中更新整个权重矩阵，LoRA只更新一小部分低秩矩阵。这种方法大大减少了需要训练的参数数量，从而降低了计算成本并加快了训练时间。尽管减少了可训练参数，使用LoRA微调的模型性能与使用传统方法微调的模型相当。</p><p>总之，LoRA通过引入一种更高效的方法来减少可训练参数的数量，解决了资源密集型的大型语言模型微调问题。这一创新不仅降低了计算和存储需求，还保持了微调模型的性能，使其成为机器学习社区中一个有价值的工具。</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2><ul><li><a href="https://huggingface.co/blog/lora" target="_blank" rel="noopener noreferrer">Using LoRA for Efficient Stable Diffusion Fine-Tuning</a></li></ul>',6),i=[n];function l(p,c){return t(),o("div",null,i)}const d=e(r,[["render",l],["__file","简介.html.vue"]]),m=JSON.parse('{"path":"/Tools/Ai/sdwebui/LoRA/%E7%AE%80%E4%BB%8B.html","title":"简介","lang":"zh-CN","frontmatter":{"title":"简介","comment":false,"editLink":false,"prev":false,"next":false,"order":1,"description":"简介 LoRA（Low-Rank Adaptation）解决了在机器学习领域，特别是微调大型语言模型时遇到的一个重大挑战。传统的微调方法需要大量的计算资源和存储空间，这对于许多用户来说是不可承受的。LoRA通过显著减少可训练参数的数量，使微调过程更加高效和可行。 LoRA通过将权重更新分解为低秩矩阵来实现这一点。与其在微调过程中更新整个权重矩阵，LoR...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/Tools/Ai/sdwebui/LoRA/%E7%AE%80%E4%BB%8B.html"}],["meta",{"property":"og:site_name","content":"一星的臭弟弟"}],["meta",{"property":"og:title","content":"简介"}],["meta",{"property":"og:description","content":"简介 LoRA（Low-Rank Adaptation）解决了在机器学习领域，特别是微调大型语言模型时遇到的一个重大挑战。传统的微调方法需要大量的计算资源和存储空间，这对于许多用户来说是不可承受的。LoRA通过显著减少可训练参数的数量，使微调过程更加高效和可行。 LoRA通过将权重更新分解为低秩矩阵来实现这一点。与其在微调过程中更新整个权重矩阵，LoR..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-07-03T23:01:39.000Z"}],["meta",{"property":"article:author","content":"Cruldra"}],["meta",{"property":"article:modified_time","content":"2024-07-03T23:01:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"简介\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-07-03T23:01:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Cruldra\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"简介","slug":"简介","link":"#简介","children":[]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]}],"git":{"createdTime":1720047699000,"updatedTime":1720047699000,"contributors":[{"name":"cruldra","email":"cruldra@gmail.com","commits":1}]},"readingTime":{"minutes":1.11,"words":334},"filePathRelative":"Tools/Ai/sdwebui/LoRA/简介.md","localizedDate":"2024年7月3日","autoDesc":true}');export{d as comp,m as data};
